{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "dz3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oPJhJ_ymHNI"
      },
      "source": [
        "### Домашнее задание"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orDcQ4W-mHNJ"
      },
      "source": [
        "1. обучить несколько разных моделей на наборе данных ССЗ (train_case2.csv): логрег, бустинг, лес и т.д - на ваш выбор 2-3 варианта\n",
        "2. при обучении моделей обязательно использовать кроссвалидацию\n",
        "3. вывести сравнение полученных моделей по основным метрикам классификации: pr/rec/auc/f_score (можно в виде таблицы, где строки - модели, а столбцы - метрики)\n",
        "4. сделать выводы о том, какая модель справилась с задачей лучше других\n",
        "5. (опциональный вопрос) какая метрика (precision_recall_curve или roc_auc_curve) больше подходит в случае сильного дисбаланса классов? (когда объектов одного из классов намного больше чем другого). \n",
        "\n",
        "p.s.В вопросе проще разобраться, если вспомнить оси на графике roc auc curve и рассмотреть такой пример:\n",
        "\n",
        "Имеется 100000 объектов, из которых только 100 - класс \"1\" (99900 - класс \"0\", соответственно). \n",
        "Допустим, у нас две модели:\n",
        "\n",
        "- первая помечает 100 объектов как класс 1, но TP = 90\n",
        "- вторая помечает 1000 объектов как класс 1, но TP такой же - 90\n",
        "\n",
        "Какая модель лучше и почему? И что позволяет легче сделать вывод - roc_auc_curve или precision_recall_curve?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXPCadsSmOVD"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUevEqYNsoEQ"
      },
      "source": [
        "В рамках конкурса вам нужно предсказать наличие сердечно-сосудистых заболеваний по результатам классического врачебного осмотра. Датасет сформирован из 100.000 реальных клинических анализов, и в нём используются признаки, которые можно разбить на 3 группы:\n",
        "\n",
        " \n",
        "\n",
        "Объективные признаки:\n",
        "\n",
        " - Возраст\n",
        " - Рост\n",
        " - Вес\n",
        " - Пол\n",
        " \n",
        "\n",
        "Результаты измерения:\n",
        "\n",
        " - Артериальное давление верхнее и нижнее\n",
        " - Холестерин\n",
        " - Глюкоза\n",
        " \n",
        "\n",
        "Субъективные признаки:\n",
        "\n",
        " - Курение\n",
        " - Употребление Алкоголя\n",
        " - Физическая активность\n",
        " \n",
        "\n",
        "Возраст дан в днях. Значения показателей холестерина и глюкозы представлены одним из трех классов: норма, выше нормы, значительно выше нормы. Значения субъективных признаков — бинарны.\n",
        "\n",
        "Все показатели даны на момент осмотра."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pe8sq8DcsoER"
      },
      "source": [
        "Таргет - наличие сердечно-сосудистых заболеваний (ССЗ)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBbNw8ImMHmo",
        "outputId": "3d3ec52c-244c-4bee-c781-bc258292276e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKXqk1jRMCaj"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import precision_recall_curve, roc_curve, roc_auc_score\n",
        "\n",
        "import itertools\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jXGrOGHsoER",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "9376ea88-7ac1-4037-c59c-fdf5906251ca"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Notebooks/ML_in_business/3/train_case2.csv', ';')\n",
        "df.head(3)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>ap_hi</th>\n",
              "      <th>ap_lo</th>\n",
              "      <th>cholesterol</th>\n",
              "      <th>gluc</th>\n",
              "      <th>smoke</th>\n",
              "      <th>alco</th>\n",
              "      <th>active</th>\n",
              "      <th>cardio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>18393</td>\n",
              "      <td>2</td>\n",
              "      <td>168</td>\n",
              "      <td>62.0</td>\n",
              "      <td>110</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>20228</td>\n",
              "      <td>1</td>\n",
              "      <td>156</td>\n",
              "      <td>85.0</td>\n",
              "      <td>140</td>\n",
              "      <td>90</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>18857</td>\n",
              "      <td>1</td>\n",
              "      <td>165</td>\n",
              "      <td>64.0</td>\n",
              "      <td>130</td>\n",
              "      <td>70</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id    age  gender  height  weight  ...  gluc  smoke  alco  active  cardio\n",
              "0   0  18393       2     168    62.0  ...     1      0     0       1       0\n",
              "1   1  20228       1     156    85.0  ...     1      0     0       1       1\n",
              "2   2  18857       1     165    64.0  ...     1      0     0       0       1\n",
              "\n",
              "[3 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLsYBHsUsoER"
      },
      "source": [
        "Разделим наши данные на тренировочную и тестовую выборки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-UqK6IDsoER"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#разделим данные на train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.drop('cardio', 1), \n",
        "                                                    df['cardio'], random_state=0)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFb3JEVUsoER"
      },
      "source": [
        "К полям:\n",
        "- gender, cholesterol применим OHE-кодирование\n",
        "- age, height, weight, ap_hi, ap_lo - standardScaler\n",
        "- gluc, smoke, alco, active - оставим пока как есть"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3GJapHwsoES"
      },
      "source": [
        "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Transformer to select a single column from the data frame to perform additional transformations on\n",
        "    \"\"\"\n",
        "    def __init__(self, key):\n",
        "        self.key = key\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X[self.key]\n",
        "    \n",
        "class NumberSelector(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Transformer to select a single column from the data frame to perform additional transformations on\n",
        "    Use on numeric columns in the data\n",
        "    \"\"\"\n",
        "    def __init__(self, key):\n",
        "        self.key = key\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X[[self.key]]\n",
        "    \n",
        "class OHEEncoder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, key):\n",
        "        self.key = key\n",
        "        self.columns = []\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.columns = [col for col in pd.get_dummies(X, prefix=self.key).columns]\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = pd.get_dummies(X, prefix=self.key)\n",
        "        test_columns = [col for col in X.columns]\n",
        "        for col_ in test_columns:\n",
        "            if col_ not in self.columns:\n",
        "                X[col_] = 0\n",
        "        return X[self.columns]\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "continuos_cols = ['age', 'height', 'weight', 'ap_hi', 'ap_lo']\n",
        "cat_cols = ['gender', 'cholesterol']\n",
        "base_cols = ['gluc', 'smoke', 'alco', 'active']\n",
        "\n",
        "continuos_transformers = []\n",
        "cat_transformers = []\n",
        "base_transformers = []\n",
        "\n",
        "for cont_col in continuos_cols:\n",
        "    transfomer =  Pipeline([\n",
        "                ('selector', NumberSelector(key=cont_col)),\n",
        "                ('standard', StandardScaler())\n",
        "            ])\n",
        "    continuos_transformers.append((cont_col, transfomer))\n",
        "    \n",
        "for cat_col in cat_cols:\n",
        "    cat_transformer = Pipeline([\n",
        "                ('selector', ColumnSelector(key=cat_col)),\n",
        "                ('ohe', OHEEncoder(key=cat_col))\n",
        "            ])\n",
        "    cat_transformers.append((cat_col, cat_transformer))\n",
        "    \n",
        "for base_col in base_cols:\n",
        "    base_transformer = Pipeline([\n",
        "                ('selector', NumberSelector(key=base_col))\n",
        "            ])\n",
        "    base_transformers.append((base_col, base_transformer))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUM-t5BtsoET"
      },
      "source": [
        "Теперь объединим все наши трансформеры с помощью FeatureUnion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Blv7gX7xsoEU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c45a0898-a012-44a4-a770-c3ce65111bc3"
      },
      "source": [
        "from sklearn.pipeline import FeatureUnion\n",
        "\n",
        "feats = FeatureUnion(continuos_transformers+cat_transformers+base_transformers)\n",
        "feature_processing = Pipeline([('feats', feats)])\n",
        "\n",
        "feature_processing.fit_transform(X_train)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.73391771,  0.6873301 ,  0.74843904, ...,  1.        ,\n",
              "         0.        ,  1.        ],\n",
              "       [-1.67343538,  0.07758923, -0.29640123, ...,  0.        ,\n",
              "         0.        ,  1.        ],\n",
              "       [ 0.13738132,  1.17512278, -0.15708919, ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       ...,\n",
              "       [ 1.17775864,  1.17512278, -0.15708919, ...,  0.        ,\n",
              "         0.        ,  1.        ],\n",
              "       [-0.47190715, -1.38578883,  0.74843904, ...,  0.        ,\n",
              "         0.        ,  1.        ],\n",
              "       [ 0.38174619,  0.56538192, -0.08743318, ...,  0.        ,\n",
              "         0.        ,  1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwpvbQ4BsoEU"
      },
      "source": [
        "**Добавим классификатор и запустим кросс-валидацию для Регрессии**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZvU6_AosoEV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b455e99f-f809-462d-e358-a4375fc6778e"
      },
      "source": [
        "classifier = Pipeline([\n",
        "    ('features',feats),\n",
        "    ('classifier', LogisticRegression(random_state = 42)),\n",
        "])\n",
        "\n",
        "\n",
        "#запустим кросс-валидацию\n",
        "cv_scores = cross_val_score(classifier, X_train, y_train, cv=16, scoring='roc_auc')\n",
        "cv_score = np.mean(cv_scores)\n",
        "cv_score_std = np.std(cv_scores)\n",
        "print('CV score is {}+-{}'.format(cv_score, cv_score_std))\n",
        "\n",
        "#обучим пайплайн на всем тренировочном датасете\n",
        "classifier.fit(X_train, y_train)\n",
        "y_score = classifier.predict_proba(X_test)[:, 1]"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CV score is 0.7867401104915408+-0.00852135511666111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-A3dU7HasoEW"
      },
      "source": [
        "Посчитаем precision/recall/f_score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cK_fvUKSsoEW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29559c2d-46aa-42af-c693-0089e07acfe5"
      },
      "source": [
        "b=1\n",
        "precision, recall, thresholds = precision_recall_curve(y_test.values, y_score)\n",
        "fscore = (1+b**2)*(precision * recall) / (b**2*precision + recall)\n",
        "# locate the index of the largest f score\n",
        "ix = np.argmax(fscore)\n",
        "print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f' % (thresholds[ix], \n",
        "                                                                        fscore[ix],\n",
        "                                                                        precision[ix],\n",
        "                                                                        recall[ix]))"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Threshold=0.386937, F-Score=0.730, Precision=0.647, Recall=0.838\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHntD63si-wu"
      },
      "source": [
        "**Создадим таблицу, куда будем записывать результат обучения моделей**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPYEg_pnIR6r"
      },
      "source": [
        "result_table = {'Classifier':[],\n",
        "                'Precision':[],\n",
        "                'Recall':[],\n",
        "                'AUC': [],\n",
        "                'F-score':[]}"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TL4DprXaiRi"
      },
      "source": [
        "**Запишем результат в таблицу**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IntkVjXaaoDB"
      },
      "source": [
        "def set_results():\n",
        "  result_table['Classifier'].append(classifier['classifier'].__class__.__name__)\n",
        "  result_table['Precision'].append(round(precision[ix], 4))\n",
        "  result_table['Recall'].append(round(recall[ix], 4))\n",
        "  result_table['F-score'].append(round(fscore[ix], 4))\n",
        "  result_table['AUC'].append('{}+-{}'.format(round(cv_score,4), round(cv_score_std,4)))\n",
        "set_results()"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hw4vEazliatX"
      },
      "source": [
        "**Дерево решений**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suht8h8cISSN"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFXCMqQDISWi",
        "outputId": "d6a0a02b-5303-4d7a-a1d4-640b80ab3d6c"
      },
      "source": [
        "classifier = Pipeline([\n",
        "    ('features',feats),\n",
        "    ('classifier', RandomForestClassifier(random_state = 42)),\n",
        "])\n",
        "\n",
        "\n",
        "#запустим кросс-валидацию\n",
        "cv_scores = cross_val_score(classifier, X_train, y_train, cv=16, scoring='roc_auc')\n",
        "cv_score = np.mean(cv_scores)\n",
        "cv_score_std = np.std(cv_scores)\n",
        "print('CV score is {}+-{}'.format(cv_score, cv_score_std))\n",
        "\n",
        "#обучим пайплайн на всем тренировочном датасете\n",
        "classifier.fit(X_train, y_train)\n",
        "y_score = classifier.predict_proba(X_test)[:, 1]"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CV score is 0.7734501681056019+-0.007171140345435727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQfpTcPdISbe",
        "outputId": "938a5a44-ccaa-4494-c6a3-92b117594d04"
      },
      "source": [
        "b=1\n",
        "precision, recall, thresholds = precision_recall_curve(y_test.values, y_score)\n",
        "fscore = (1+b**2)*(precision * recall) / (b**2*precision + recall)\n",
        "# locate the index of the largest f score\n",
        "ix = np.argmax(fscore)\n",
        "print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f' % (thresholds[ix], \n",
        "                                                                        fscore[ix],\n",
        "                                                                        precision[ix],\n",
        "                                                                        recall[ix]))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Threshold=0.350000, F-Score=0.719, Precision=0.643, Recall=0.816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Acl8a5rJOySJ"
      },
      "source": [
        "set_results()"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqcsKb0Qinnc"
      },
      "source": [
        "**XGBoost**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JwE_0oqOyZO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55bf3789-202b-4916-87f8-c424283e5d7f"
      },
      "source": [
        "!pip install xgboost"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z28f6fIyOyu4"
      },
      "source": [
        "from xgboost import XGBClassifier"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCHEigRpUbg8",
        "outputId": "784dcadb-c05c-45f1-9ab1-99192fa4de28"
      },
      "source": [
        "classifier = Pipeline([\n",
        "    ('features',feats),\n",
        "    ('classifier', XGBClassifier(random_state = 42)),\n",
        "])\n",
        "\n",
        "\n",
        "#запустим кросс-валидацию\n",
        "cv_scores = cross_val_score(classifier, X_train, y_train, cv=16, scoring='roc_auc')\n",
        "cv_score = np.mean(cv_scores)\n",
        "cv_score_std = np.std(cv_scores)\n",
        "print('CV score is {}+-{}'.format(cv_score, cv_score_std))\n",
        "\n",
        "#обучим пайплайн на всем тренировочном датасете\n",
        "classifier.fit(X_train, y_train)\n",
        "y_score = classifier.predict_proba(X_test)[:, 1]"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CV score is 0.8025763708244553+-0.006962037806505938\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnhx6MH0UboX",
        "outputId": "5c5a8d73-eb1e-45b5-8529-f077685e4dc0"
      },
      "source": [
        "b=1\n",
        "precision, recall, thresholds = precision_recall_curve(y_test.values, y_score)\n",
        "fscore = (1+b**2)*(precision * recall) / (b**2*precision + recall)\n",
        "# locate the index of the largest f score\n",
        "ix = np.argmax(fscore)\n",
        "print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f' % (thresholds[ix], \n",
        "                                                                        fscore[ix],\n",
        "                                                                        precision[ix],\n",
        "                                                                        recall[ix]))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Threshold=0.917578, F-Score=nan, Precision=0.000, Recall=0.000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vpuln18Zuwom",
        "outputId": "52ac2087-e122-4a56-be6a-33312891e238"
      },
      "source": [
        "len(precision)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13167"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6dMKNVA1SDb",
        "outputId": "ae25f1d3-0908-4c9c-b6d7-d3ec32ef92a0"
      },
      "source": [
        "recall"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.00000000e+00, 9.99884793e-01, 9.99884793e-01, ...,\n",
              "       1.15207373e-04, 0.00000000e+00, 0.00000000e+00])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McdfnBv2i3B1"
      },
      "source": [
        "set_results()"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbbgW6lwkBwn"
      },
      "source": [
        "**Выведем результат моделей**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "dWSo442mi3RD",
        "outputId": "d26e94fc-6682-487b-9314-3efe96ec4866"
      },
      "source": [
        "df = pd.DataFrame(result_table)\n",
        "df"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>AUC</th>\n",
              "      <th>F-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.6474</td>\n",
              "      <td>0.8376</td>\n",
              "      <td>0.7867+-0.0085</td>\n",
              "      <td>0.7303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.6427</td>\n",
              "      <td>0.8156</td>\n",
              "      <td>0.7735+-0.0072</td>\n",
              "      <td>0.7189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.8026+-0.007</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Classifier  Precision  Recall             AUC  F-score\n",
              "0      LogisticRegression     0.6474  0.8376  0.7867+-0.0085   0.7303\n",
              "1  RandomForestClassifier     0.6427  0.8156  0.7735+-0.0072   0.7189\n",
              "2           XGBClassifier     0.0000  0.0000   0.8026+-0.007      NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJ09lRw8i3qr"
      },
      "source": [
        ""
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCmld-Wz7STQ"
      },
      "source": [
        "В случае сильного дисбаланса классов необходимо использовать precision_recall_curve. Roc_auc_curve лучше использовать когда примерно одинаковое количество измерений каждого класса.\n",
        "В случае дисбаланса roc_auc_curve может ввести в збслуждение насчет качества алгоритма."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IAUrqmI7StS"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZY6b5HGsoEa"
      },
      "source": [
        "1. https://dyakonov.org/2017/07/28/auc-roc-площадь-под-кривой-ошибок/\n",
        "2. https://en.wikipedia.org/wiki/Receiver_operating_characteristic"
      ]
    }
  ]
}